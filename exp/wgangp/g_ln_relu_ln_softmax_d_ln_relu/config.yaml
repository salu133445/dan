# Model
data_shape: [28, 28, 1]
n_classes: 10
nets:
  generator: ln_relu_ln_softmax
  discriminator: ln_relu

# Experiment
validation_steps: 100
log_validation: true
log_loss_steps: 100 # set to 0 to disable loss logging
save_summaries_steps: 0 # set to 0 to disable saving summaries
save_checkpoint_steps: 0 # set to 0 to disable saving checkpoints

# Data
data_source: 'sa' # 'sa', 'npy', 'npz'
train_x_filename: mnist_train_x
train_y_filename: mnist_train_y
val_x_filename: mnist_val_x
val_y_filename: mnist_val_y

# Training
steps: 100000
batch_size: 64
n_dis_updates_per_gen_update: 5

# Optimizers
learning_rate: 0.001
adam:
  beta1: 0.5
  beta2: 0.9

# Losses
gan_loss_type: wasserstein # nonsaturating, classic, wasserstein, hinge
use_gradient_penalties: true
weight_clipping_threshold: 0.01
